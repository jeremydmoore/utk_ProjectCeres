{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing OpenCV's EAST text detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "from shutil import copy\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytesseract\n",
    "from fuzzywuzzy import fuzz, process\n",
    "from imutils.object_detection import non_max_suppression\n",
    "from ipywidgets import IntProgress, Label, VBox\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image, ImageFilter\n",
    "from skimage.measure import compare_ssim as ssim\n",
    "\n",
    "import img_qc.img_qc as img_qc\n",
    "\n",
    "plt.rc('figure', figsize=(20.0, 10.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     7,
     20
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def get_top_percent_of_image(cv2_image, percentage):\n",
    "    height, width = cv2_image.shape[:2]\n",
    "    x1, y1, x2, y2 = 0, 0, width, int(height * percentage)\n",
    "    image_cropped = cv2_image[y1:y2, x1:x2]\n",
    "    return image_cropped\n",
    "\n",
    "\n",
    "def crop_image_for_ocr(image_path, percentage=0.4, top_and_sides_padding=100):\n",
    "    image = cv2.imread(str(image_path))\n",
    "    height, width = image.shape[:2]\n",
    "    x1, y1, x2, y2 = 0, 0, width, int(height * percentage)\n",
    "    x1 += top_and_sides_padding\n",
    "    y1 += top_and_sides_padding\n",
    "    x2 -= top_and_sides_padding\n",
    "    y2 += top_and_sides_padding\n",
    "    image = image[y1:y2, x1:x2]\n",
    "    return image\n",
    "\n",
    "\n",
    "def if_rgb_convert_to_gray(np_image):\n",
    "    if len(np_image.shape) > 2:\n",
    "        np_image = cv2.cvtColor(np_image, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "    return np_image\n",
    "\n",
    "\n",
    "def bgr_imshow(bgr_image):\n",
    "    bgr_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(bgr_image)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def decode_predictions(scores, geometry):\n",
    "    # grab the number of yas and columns from the scores volume, then\n",
    "    # initialize our set of bounding box rectangles and corresponding\n",
    "    # confidence socres\n",
    "    (number_of_rows, number_of_columns) = scores.shape[2:4]\n",
    "    rectangles = []\n",
    "    confidences = []\n",
    "\n",
    "    # loop over the number of ys\n",
    "    for y in range(0, number_of_rows):\n",
    "        # extract the scores (probabilities), followed by the geometrical\n",
    "        # data used to derive potential bounding box coordinates that surround text\n",
    "        scores_data = scores[0, 0, y]\n",
    "        x_data_0 = geometry[0, 0, y]\n",
    "        x_data_1 = geometry[0, 1, y]\n",
    "        x_data_2 = geometry[0, 2, y]\n",
    "        x_data_3 = geometry[0, 3, y]\n",
    "        angles_data = geometry[0, 4, y]\n",
    "\n",
    "        # loop over the number of columns\n",
    "        for x in range(0, number_of_columns):\n",
    "            # if our score does not have a sufficient probability, ignore it\n",
    "            # print(f'confidence/min confidence: {scores_data[x]}/{minimum_confidence}')\n",
    "            if scores_data[x] < minimum_confidence:\n",
    "                continue\n",
    "\n",
    "            # compute the offset factor as our resulting feature maps will\n",
    "            # be 4x smaller than the input image\n",
    "            (offset_x, offset_y) = (x * 4.0, y * 4.0)\n",
    "\n",
    "            # extract the rotation angle for the prediction and then\n",
    "            # compute sin and cosine\n",
    "            angle = angles_data[x]\n",
    "            cos = np.cos(angle)\n",
    "            sin = np.sin(angle)\n",
    "\n",
    "            # use the geometry volume to derive the width and height of the bounding box\n",
    "            bounding_box_height = x_data_0[x] + x_data_2[x]\n",
    "            bounding_box_width = x_data_1[x] + x_data_3[x]\n",
    "\n",
    "            # compute both the starting and ending (x, y)-coordinates for the\n",
    "            # text prediction bounding box\n",
    "            end_x = int(offset_x + (cos * x_data_1[x]) + (sin * x_data_2[x]))\n",
    "            end_y = int(offset_y - (sin * x_data_1[x]) + (cos * x_data_2[x]))\n",
    "            start_x = int(end_x - bounding_box_width)\n",
    "            start_y = int(end_y - bounding_box_height)\n",
    "\n",
    "            # add bounding box coordinates and probability score to respective lists\n",
    "            rectangles.append((start_x, start_y, end_x, end_y))\n",
    "            confidences.append(scores_data[x])\n",
    "        \n",
    "    # return a tuple of the bounding boxes and associated confidences\n",
    "    return (rectangles, confidences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "data_dir_path = Path('/Volumes/fluffy/ProjectCeres/00_for_CRL/agrtfn')\n",
    "\n",
    "page_1_paths_list = sorted(data_dir_path.glob('**/*_0001.tif'))\n",
    "# remove macOS '.' index files\n",
    "page_1_paths_list = [x for x in page_1_paths_list if not str(x.stem).startswith('.')]\n",
    "len(page_1_paths_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# progress bar\n",
    "progress_label = Label('Images to copy')\n",
    "progress_bar = IntProgress(min=0, max=len(page_1_paths_list))\n",
    "progress_widget = VBox([progress_label, progress_bar])\n",
    "display(progress_widget)\n",
    "\n",
    "# download copies of all page 1 files\n",
    "for index, image_path in enumerate(page_1_paths_list, start=1):\n",
    "    progress_label.value = image_path.name\n",
    "    copy_to_path = Path('data/').joinpath(image_path.name)\n",
    "    copy(image_path, copy_to_path)\n",
    "    progress_bar.value = index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is processing all issues in {data_dir_path} from the Tennessee Farm News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_path = Path('data/')\n",
    "page_1_paths_list = sorted(data_dir_path.glob('images/*.tif'))\n",
    "page_1_paths_list = [x for x in page_1_paths_list if not str(x.stem).startswith('.')]\n",
    "print(f'{len(page_1_paths_list)} images in page 1 paths list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_grayscale = 0\n",
    "number_of_rgb = 0\n",
    "gray_image_paths_list = []\n",
    "rgb_image_paths_list = []\n",
    "for image_path in page_1_paths_list:\n",
    "    image = Image.open(image_path)\n",
    "    if image.mode == 'L':\n",
    "        number_of_grayscale += 1\n",
    "        gray_image_paths_list.append(image_path)\n",
    "    elif image.mode == 'RGB':\n",
    "        number_of_rgb += 1\n",
    "        rgb_image_paths_list.append(image_path)\n",
    "print(f'# of grayscale: {number_of_grayscale}')\n",
    "print(f'      # of rgb: {number_of_rgb}')\n",
    "print(f'  total images: {number_of_grayscale + number_of_rgb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = page_1_paths_list[2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = [\n",
    "    'january',\n",
    "    'february',\n",
    "    'march',\n",
    "    'april',\n",
    "    'may',\n",
    "    'june',\n",
    "    'july',\n",
    "    'august',\n",
    "    'september',\n",
    "    'october',\n",
    "    'november',\n",
    "    'december'\n",
    "]\n",
    "\n",
    "def return_date(image):\n",
    "    \n",
    "    date = []\n",
    "    \n",
    "    # blur image and convert to grayscale if necessary\n",
    "    image = cv2.bilateralFilter(image, 9, 9, 9)\n",
    "    # image = cv2.GaussianBlur(image, (9, 9), 0)\n",
    "    if len(image.shape) > 2:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # show image    \n",
    "    # plt.imshow(image, cmap='gray'), plt.show()\n",
    "    \n",
    "    # binarize\n",
    "    binarized = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 55, 11)\n",
    "    \n",
    "    # OCR\n",
    "    config='-c tessedit_char_whitelist=0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\\  --psm 6'\n",
    "    ocr_text = pytesseract.image_to_string(binarized, lang='eng', config=config)\n",
    "    # Get verbose data including boxes, confidences, line and page numbers\n",
    "    ocr_dataframe = pytesseract.image_to_data(binarized, lang='eng', output_type=pytesseract.Output.DATAFRAME, config=config)\n",
    "    test_boxes = pytesseract.image_to_boxes(binarized, lang='eng', config=config)\n",
    "    \n",
    "    # split OCR results and look for \"months\"\n",
    "    # for line in text.split('\\n'):\n",
    "    #     words = line.split()\n",
    "    #     for index, word in enumerate(words):\n",
    "    #         if word.lower() in months:\n",
    "    #             date.append(words[index:])\n",
    "                \n",
    "    # plt.imshow(binarized, cmap='gray'), plt.show()\n",
    "    \n",
    "    return ocr_dataframe, ocr_text, binarized, test_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_box_list = ['text', 'left', 'top', 'width', 'height']\n",
    "\n",
    "ocr_dataframe = return_date(image_path)\n",
    "for index, ocr_result in enumerate(ocr_dataframe['text']):\n",
    "    if isinstance(ocr_result, float):\n",
    "        pass\n",
    "    else:\n",
    "        if ocr_result.lower() in months:\n",
    "            # print(ocr_dataframe.iloc[index])\n",
    "            box = []\n",
    "            for edge in roi_box_list:\n",
    "                box.append(ocr_dataframe.iloc[index][edge])\n",
    "# print(box)\n",
    "\n",
    "print(box)\n",
    "box = [int(x) if x != box[0] else x for x in box]\n",
    "text, x1, y1, box_width, box_height = box\n",
    "x2 = x1 + box_width\n",
    "y2 = y1 + box_height\n",
    "\n",
    "# print(box)\n",
    "image_to_crop = cv2.imread(str(image_path))\n",
    "image_cropped = image_to_crop[y1:y2, x1:x2]\n",
    "bgr_imshow(image_cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deskew(image):\n",
    "\n",
    "    # convert the image to grayscale and flip the foreground\n",
    "    # and background to ensure foreground is now \"white\" and\n",
    "    # the background is \"black\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # threshold the image, setting all foreground pixels to\n",
    "    # 255 and all background pixels to 0\n",
    "    gray = cv2.medianBlur(gray, 5)\n",
    "    gray = cv2.bitwise_not(gray)\n",
    "    binarized = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "    # binarized = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 55, 11)\n",
    "    # plt.imshow(binarized, cmap='gray'), plt.show()\n",
    "    \n",
    "    # grab the (x, y) coordinates of all pixel values that\n",
    "    # are greater than zero, then use these coordinates to\n",
    "    # compute a rotated bounding box that contains all\n",
    "    # coordinates\n",
    "    coords = np.column_stack(np.where(binarized > 0))\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "\n",
    "    # the `cv2.minAreaRect` function returns values in the\n",
    "    # range [-90, 0); as the rectangle rotates clockwise the\n",
    "    # returned angle trends to 0 -- in this special case we\n",
    "    # need to add 90 degrees to the angle\n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    "\n",
    "    # otherwise, just take the inverse of the angle to make\n",
    "    # it positive\n",
    "    else:\n",
    "        angle = -angle\n",
    "    \n",
    "    # print(angle)\n",
    "    # rotate the image to deskew it\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    # bgr_imshow(image)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    # bgr_imshow(rotated)\n",
    "    \n",
    "    return rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "percentage = 0.4\n",
    "\n",
    "for image_path in page_1_paths_list[1500:1503]:\n",
    "    print(image_path.stem)\n",
    "    image = cv2.imread(str(image_path))\n",
    "    height, width = image.shape[:2]\n",
    "    x1, y1, x2, y2 = 0, 0, width, int(height * percentage)\n",
    "    top_and_sides_padding = 100\n",
    "    x1 += top_and_sides_padding\n",
    "    y1 += top_and_sides_padding\n",
    "    x2 -= top_and_sides_padding\n",
    "    y2 += top_and_sides_padding\n",
    "    image = image[y1:y2, x1:x2]\n",
    "    \n",
    "    rotated = deskew(image)\n",
    "    \n",
    "    variables = [ocr_dataframe, box, text, x1, y1, box_width, box_height, x2, y2]\n",
    "    for variable in variables:\n",
    "        variable = ''\n",
    "    \n",
    "    # OCR and load results as Pandas dataframe\n",
    "    ocr_dataframe, ocr_text, binarized, test_boxes = return_date(rotated)\n",
    "    \n",
    "    words = ocr_text.lower().split()\n",
    "    best_word = {}\n",
    "    best_ratio = 90\n",
    "    for month in months:\n",
    "        # print(month)\n",
    "        result = process.extractOne(month, words)\n",
    "        word, ratio = result[:2]\n",
    "        if ratio > best_ratio:\n",
    "            best_word.update({month: word})\n",
    "    print(best_word)\n",
    "    print(100 * '*')\n",
    "    print(test_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "percentage = 0.4\n",
    "top_and_sides_padding = 100\n",
    "roi_box_list = ['text', 'left', 'top', 'width', 'height']\n",
    "\n",
    "for image_path in page_1_paths_list[::100]:\n",
    "    print(image_path.stem)\n",
    "    \n",
    "    variables = [ocr_dataframe, ocr_text, binarized, box, text, x1, y1, box_width, box_height, x2, y2]\n",
    "    for variable in variables:\n",
    "        variable = ''\n",
    "    \n",
    "    image = crop_image_for_ocr(image_path, percentage=percentage, top_and_sides_padding=top_and_sides_padding)\n",
    "    \n",
    "    original = image.copy()\n",
    "    \n",
    "    # OCR and load results as Pandas dataframe\n",
    "    ocr_dataframe, ocr_text, binarized = return_date(image)\n",
    "    \n",
    "    find_date = True\n",
    "    for index, ocr_result in enumerate(ocr_dataframe['text']):\n",
    "        if find_date:\n",
    "            # print(find_date)\n",
    "            if isinstance(ocr_result, float):  # skip NaN values\n",
    "                pass\n",
    "            else:\n",
    "                if ocr_result.lower() in months:\n",
    "                    box_month, box_day, box_year = [], [], []\n",
    "                    boxes = [box_month, box_day, box_year]\n",
    "                    for box in boxes:\n",
    "                        if isinstance(ocr_dataframe.iloc[index]['text'], str):  # skip NaN values\n",
    "                            for data in roi_box_list:\n",
    "                                box.append(ocr_dataframe.iloc[index][data])\n",
    "                            index += 1\n",
    "                    find_date = False\n",
    "                    # print('NOW FALSE')\n",
    "    if not find_date:\n",
    "        if len(image.shape) < 3:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "        bgr_imshow(image)\n",
    "        plt.imshow(binarized, cmap='gray'), plt.show()\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 3, figsize=(30, 10))\n",
    "        fig.suptitle(image_path.stem, fontsize=16)\n",
    "        for index, box in enumerate(boxes):\n",
    "            print(index, box)\n",
    "\n",
    "            box = [int(x) if x != box[0] else x for x in box]\n",
    "            try: \n",
    "                text, x1, y1, box_width, box_height = box\n",
    "                x2 = x1 + box_width\n",
    "                y2 = y1 + box_height\n",
    "\n",
    "                # print(box)\n",
    "                \n",
    "                image_cropped = image[y1:y2, x1:x2]\n",
    "                image_cropped_rgb = cv2.cvtColor(image_cropped, cv2.COLOR_BGR2RGB)\n",
    "                axes[index].imshow(image_cropped_rgb)\n",
    "                axes[index].set_title(text)\n",
    "            except ValueError:\n",
    "                pass\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('No date found')\n",
    "        \n",
    "        if len(original.shape) < 3:\n",
    "            original = cv2.cvtColor(original, cv2.COLOR_GRAY2BGR)\n",
    "        bgr_imshow(original)\n",
    "        plt.imshow(binarized, cmap='gray'), plt.show()\n",
    "    print(ocr_text)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(30, 10))\n",
    "\n",
    "for index, box in enumerate(boxes):\n",
    "    print(box)\n",
    "    box = [int(x) if x != box[0] else x for x in box]\n",
    "    text, x1, y1, box_width, box_height = box\n",
    "    x2 = x1 + box_width\n",
    "    y2 = y1 + box_height\n",
    "\n",
    "    # print(box)\n",
    "    image_to_crop = cv2.imread(str(image_path))\n",
    "    image_cropped = image_to_crop[y1:y2, x1:x2]\n",
    "    image_cropped_rgb = cv2.cvtColor(image_cropped, cv2.COLOR_BGR2RGB)\n",
    "    axes[index].imshow(image_cropped_rgb)\n",
    "    axes[index].set_title(text)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(str(image_path))\n",
    "\n",
    "image = get_top_percent_of_image(image, 0.3)\n",
    "\n",
    "bgr_imshow(image)\n",
    "\n",
    "#image = cv2.resize(image,(0,0),fx=7,fy=7)\n",
    "\n",
    "image = cv2.GaussianBlur(image,(9,9),0)\n",
    "\n",
    "#image = cv2.medianBlur(image,9)\n",
    "\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "image = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 55, 11) \n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "#bgr_imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config='-c tessedit_char_whitelist=0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ,\\  --psm 6'\n",
    "text = pytesseract.image_to_string(image,\n",
    "                                   lang='eng',\n",
    "                                   config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = [\n",
    "    'january',\n",
    "    'february',\n",
    "    'march',\n",
    "    'april',\n",
    "    'may',\n",
    "    'june',\n",
    "    'july',\n",
    "    'august',\n",
    "    'september',\n",
    "    'october',\n",
    "    'november',\n",
    "    'december'\n",
    "]\n",
    "\n",
    "for line in text.split('\\n'):\n",
    "    words = line.split()\n",
    "    for index, word in enumerate(words):\n",
    "        if word.lower() in months:\n",
    "            print(word)\n",
    "            print(words[index:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = page_1_paths_list[-100]\n",
    "resize_width = 1600  # must be a multiple of 32\n",
    "resize_height = 1600  # must be a multiple of 32\n",
    "minimum_confidence = 0.5\n",
    "padding = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load input image and get dimensions\n",
    "image = cv2.imread(str(image_path))\n",
    "original = image.copy()\n",
    "(original_height, original_width) = image.shape[:2]\n",
    "\n",
    "# set the new width and height then determine the ration in change\n",
    "(new_width, new_height) = resize_width, resize_height\n",
    "ratio_width = original_width / float(new_width)\n",
    "ratio_height = original_height / float(new_height)\n",
    "\n",
    "# resize the image and get the new dimensions\n",
    "image = cv2.resize(image, (new_width, new_height))\n",
    "(height, width) = image.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the two output layer names for the EAST detector model\n",
    "# 1st: output probabilities\n",
    "# 2nd: used to derive the bounding box coordinates of text\n",
    "layer_names = [\n",
    "    \"feature_fusion/Conv_7/Sigmoid\",\n",
    "    \"feature_fusion/concat_3\"\n",
    "]\n",
    "\n",
    "# load the pre-trained EAST detector\n",
    "print(\"[INFO] loading EAST text detector . . . \")\n",
    "net = cv2.dnn.readNet('data/frozen_east_text_detection.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a blob from the image and perform a forward pass of the model\n",
    "# to obtain the two output layer sets\n",
    "blob = cv2.dnn.blobFromImage(image, 1.0, (width, height), \n",
    "                             (123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
    "start = time.time()\n",
    "net.setInput(blob)\n",
    "(scores, geometry) = net.forward(layer_names)\n",
    "end = time.time()\n",
    "\n",
    "# show timing information on text predition\n",
    "print(f'[INFO] text detection took {round((end - start), 6)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# grab the number of rows and columns from the scores volume, then\n",
    "# initialize our set of bounding box rectangles and corresponding\n",
    "# confidence scores\n",
    "(number_of_rows, number_of_columns) = scores.shape[2:4]\n",
    "rectangles = []\n",
    "confidences = []\n",
    "\n",
    "# loop over the number of ys\n",
    "for y in range(0, number_of_rows):\n",
    "    # extract the scores (probabilities), followed by the geometrical\n",
    "    # data used to derive potential bounding box coordinates that surround text\n",
    "    scores_data = scores[0, 0, y]\n",
    "    x_data_0 = geometry[0, 0, y]\n",
    "    x_data_1 = geometry[0, 1, y]\n",
    "    x_data_2 = geometry[0, 2, y]\n",
    "    x_data_3 = geometry[0, 3, y]\n",
    "    angles_data = geometry[0, 4, y]\n",
    "    \n",
    "    # loop over the number of columns\n",
    "    for x in range(0, number_of_columns):\n",
    "        # if our score does not have a sufficient probability, ignore it\n",
    "        if scores_data[x] < minimum_confidence:\n",
    "            continue\n",
    "        \n",
    "        # compute the offset factor as our resulting feature maps will\n",
    "        # be 4x smaller than the input image\n",
    "        (offset_x, offset_y) = (x * 4.0, y * 4.0)\n",
    "        \n",
    "        # extract the rotation angle for the prediction and then\n",
    "        # compute sin and cosine\n",
    "        angle = angles_data[x]\n",
    "        cos = np.cos(angle)\n",
    "        sin = np.sin(angle)\n",
    "        \n",
    "        # use the geometry volume to derive the width and height of the bounding box\n",
    "        bounding_box_height = x_data_0[x] + x_data_2[x]\n",
    "        bounding_box_width = x_data_1[x] + x_data_3[x]\n",
    "        \n",
    "        # compute both the starting and ending (x, y)-coordinates for the\n",
    "        # text prediction bounding box\n",
    "        end_x = int(offset_x + (cos * x_data_1[x]) + (sin * x_data_2[x]))\n",
    "        end_y = int(offset_y - (sin * x_data_1[x]) + (cos * x_data_2[x]))\n",
    "        start_x = int(end_x - bounding_box_width)\n",
    "        start_y = int(end_y - bounding_box_height)\n",
    "        \n",
    "        # add bounding box coordinates and probability score to respective lists\n",
    "        rectangles.append((start_x, start_y, end_x, end_y))\n",
    "        confidences.append(scores_data[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# apply non-maxima suppression to suppress weak, overlapping bouding boxes\n",
    "boxes = non_max_suppression(np.array(rectangles), probs=confidences)\n",
    "\n",
    "# loop over the bounding boxes\n",
    "for (start_x, start_y, end_x, end_y) in boxes:\n",
    "    # scale the bounding box coordinates based on the respective ratios\n",
    "    start_x = int(start_x * ratio_width)\n",
    "    start_y = int(start_y * ratio_height)\n",
    "    end_x = int(end_x * ratio_width)\n",
    "    end_y = int(end_y * ratio_height)\n",
    "    \n",
    "    # draw the bounding box on the image\n",
    "    cv2.rectangle(original, (start_x, start_y), (end_x, end_y), (0, 255, 0), 8)\n",
    "\n",
    "# show the output image\n",
    "bgr_imshow(original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_confidence = 0.9\n",
    "padding = 5\n",
    "(rectangles, confidences) = decode_predictions(scores, geometry)\n",
    "\n",
    "# apply non-maxima suppression to suppress weak, overlapping bouding boxes\n",
    "boxes = non_max_suppression(np.array(rectangles), probs=confidences)\n",
    "\n",
    "# initialize the list of results\n",
    "results = []\n",
    "\n",
    "# loop over the bounding boxes\n",
    "for (start_x, start_y, end_x, end_y) in boxes:\n",
    "    # scale the bounding box coordinates based on the respective ratios\n",
    "    start_x = int(start_x * ratio_width)\n",
    "    start_y = int(start_y * ratio_height)\n",
    "    end_x = int(end_x * ratio_width)\n",
    "    end_y = int(end_y * ratio_height)\n",
    "    \n",
    "    # obtain a better OCR by adding padding\n",
    "    delta_x = int((end_x - start_x) * padding)\n",
    "    delta_y = int((end_y - start_y) * padding)\n",
    "    \n",
    "    # apply the padding to each side of the bounding box\n",
    "    start_x = max(0, start_x - delta_x)\n",
    "    start_y = max(0, start_y - delta_y)\n",
    "    end_x = min(original_width, end_x + (delta_x * 2))\n",
    "    end_y = min(original_height, end_y + (delta_y * 2))\n",
    "    \n",
    "    # extract the actual padded ROI\n",
    "    roi = original[start_y:end_y, start_x:end_x]\n",
    "    \n",
    "    # set tesseract parameters\n",
    "    # language: english, oem: 1, LSTM neural net model, psm: 7, single line of text\n",
    "    config = (\"-l eng --oem 1 --psm 7\")\n",
    "    text = pytesseract.image_to_string(roi, config=config)\n",
    "    \n",
    "    # add the bounding box coordinates and OCR'd text to the list of results\n",
    "    results.append(((start_x, start_y, end_x, end_y), text))\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sort the results bounding box coordinates from top to bottom\n",
    "results = sorted(results, key=lambda r:r[0][1])\n",
    "\n",
    "# loop over the results\n",
    "for ((start_x, start_y, end_x, end_y), text) in results[:10]:\n",
    "    # display the text OCR'd by Tesseract\n",
    "    print('OCR TEXT')\n",
    "    print('========')\n",
    "    print(f'{text}\\n')\n",
    "    \n",
    "    # strip out the non-ASCII text and draw the texton the image using OpenCV\n",
    "    # draw the text and a bounding box surrounding the text region of the input image\n",
    "    text = ''.join([c if ord(c) < 128 else \"\" for c in text]).strip()\n",
    "    output = original.copy()\n",
    "    cv2.rectangle(output, (start_x, start_y), (end_x, end_y),\n",
    "                 (0, 0, 255), 6)\n",
    "    cv2.putText(output, text, (start_x, start_y - 20),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 9)\n",
    "    \n",
    "    # show the output image\n",
    "    bgr_imshow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
